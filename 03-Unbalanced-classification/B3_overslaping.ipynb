{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1718ac6b",
   "metadata": {},
   "source": [
    "Sobremuestreo\n",
    "\n",
    "¿Cómo podemos hacer que las observaciones de una clase rara sean menos raras en los datos?\n",
    "\n",
    "Ahora obtienes 1 punto por resolver cualquier tarea en la prueba. Las tareas más importantes se repiten varias veces para que sean más fáciles de recordar.\n",
    "\n",
    "En el entrenamiento de modelos, esta técnica se denomina sobremuestreo.\n",
    "\n",
    "El sobremuestreo se realiza, por lo general, en cuatro pasos:\n",
    "\n",
    "Se divide el dataset de entrenamiento en observaciones negativas y positivas.\n",
    "Se duplican varias veces las observaciones positivas (las que raramente ocurren).\n",
    "Se crea una nueva muestra de entrenamiento con base en los datos obtenidos.\n",
    "Se mezclan los datos: hacer la misma pregunta una y otra vez no ayudará al entrenamiento.\n",
    "Comencemos por implementar estos pasos en los siguientes ejercicios. Te guiaremos a lo largo de todo el proceso.\n",
    "\n",
    "1.\n",
    "\n",
    "Hemos dividido los datos en datos de entrenamiento y datos de prueba. Tu tarea consistirá en dividir el dataset de entrenamiento en cuatro variables del siguiente modo:\n",
    "\n",
    "features_zeros — características de las observaciones de la respuesta \"0\"\n",
    "features_ones — características de las observaciones de la respuesta \"1\"\n",
    "target_zeros — objetivo de las observaciones de la respuesta \"0\"\n",
    "target_ones — objetivo de las observaciones de la respuesta \"1\"\n",
    "\n",
    "Muestra en la pantalla los tamaños de las cuatro tablas almacenadas en las variables (ya en el precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# < escribe el código aquí>\n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "print(features_zeros.shape)\n",
    "print(features_ones.shape)\n",
    "print(target_zeros.shape)\n",
    "print(target_ones.shape)\n",
    "\n",
    "\"\"\"\n",
    "(37411, 196)\n",
    "(584, 196)\n",
    "(37411,)\n",
    "(584,)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ff213",
   "metadata": {},
   "source": [
    "2. Se pueden duplicar observaciones \"n\" número de veces utilizando la sintaxis de multiplicación de listas de Python. Para repetir los elementos de la lista, la lista se multiplica por un número entero (el número requerido de repeticiones). Aquí tienes un ejemplo:\n",
    "\n",
    "answers = [0, 1, 0]\n",
    "print(answers)\n",
    "\n",
    "answers_x3 = answers * 3\n",
    "print(answers_x3)\n",
    "\n",
    "[0, 1, 0]\n",
    "[0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "\n",
    "Tu tarea es abordar el desequilibrio de clases al: \n",
    "\n",
    "1. Identicar la clase subrepresentada (clase positiva).\n",
    "2. Duplicar estas observaciones de clase positivas. El número de repeticiones se almacena en la variable repeat.\n",
    "\n",
    "3. Combinar las observaciones de clase positivas duplicadas con las observaciones de clase negativas.\n",
    "\n",
    "4. Utiliza la función pd.concat() para realizar esta combinación.\n",
    "5. Consultar la documentación de pd.concat() para conocer los detalles sobre cómo utilizar la función.\n",
    "\n",
    "6. Almacenar las características combinadas en la variable features_upsampled.\n",
    "7. Repetir el proceso de duplicación para el objetivo y almacena el resultado en la variable target_upsampled.\n",
    "\n",
    "8. Muestra los tamaños de las nuevas variables (en el precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "repeat = 10\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)\n",
    "\n",
    "#(43251, 196)\n",
    "#(43251,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fe283",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Utilizaremos lo que hemos programado en los ejercicios anteriores y lo implementaremos dentro de la función upsample(). La función tiene que:\n",
    "\n",
    "1. Manejar tres parámetros: features, target y repeat .\n",
    "2. Dividir features y target en dataframes/series para la clase 0 y la clase 1. (Ejercicio 1)\n",
    "3. Duplicar: Repetir los datos de la clase 1 repeat veces (Ejercicio 2).\n",
    "4. Concatenar: Combinar los datos de la clase 0 con los datos repetidos de la clase 1 utilizando pd.concat() (Ejercicio 2).\n",
    "5. Mezclar los datos combinados con shuffle() con un random_state de tu elección.\n",
    "6. Devolver las características mezcladas y el objetivo.\n",
    "\n",
    "Por último, llamarás a la función de los datos entrenados y mostrarás los tamaños de las muestras (en el precódigo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# < crear la función a partir del siguiente código >\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "    \n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "repeat = 10\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "# < añadir aleatorio >\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 10\n",
    ")\n",
    "\n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)\n",
    "\n",
    "#(43251, 196)\n",
    "#(43251,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d7890",
   "metadata": {},
   "source": [
    "4. Entrena el modelo LogisticRegression con los nuevos datos. Encuentra el valor F1 y muéstralo en la pantalla (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 10\n",
    ")\n",
    "\n",
    "# < escribe el código aquí >\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "#F1: 0.13688212927756654"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032b3de",
   "metadata": {},
   "source": [
    "Nuestra métrica está mejorando constantemente gracias al sobremuestreo! Esta técnica ayuda al modelo a reconocer y clasificar mejor las instancias de clase minoritaria, lo que finalmente aumenta nuestro valor F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_csv('/datasets/travel_insurance_us_preprocessed.csv')\n",
    "\n",
    "target = data['Claim']\n",
    "features = data.drop('Claim', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.1\n",
    ")\n",
    "\n",
    "# < escribe el código aquí >\n",
    "model = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "\n",
    "#F1: 0.13333333333333333"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
